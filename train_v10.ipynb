{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BHZnXywjxGeq"
   },
   "outputs": [],
   "source": [
    "#https://pytorch.org/tutorials/beginner/transformer_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kY_j8RUDP5y4"
   },
   "outputs": [],
   "source": [
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import math\n",
    "from torch.autograd.variable import Variable\n",
    "import typing\n",
    "import random\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "y4lRdOSZNpe2"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ph2WO5JpKukk",
    "outputId": "ab00d895-307a-4ade-e705-1c6dd8ae6926"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "modelname=\"5_2_23_m1\"\n",
    "\n",
    "prefix_models=\"models/\"+modelname+\"/\"\n",
    "\n",
    "if not os.path.exists(prefix_models):\n",
    "    os.makedirs(prefix_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Oe3wtt5oADl6"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xGOoJdNdRSaO"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        #mine is [batch, seq, embed]\n",
    "        x = x.permute((1,0,2))\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        dropout = self.dropout(x)\n",
    "        return dropout.permute((1,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XakHZ4HfFdYM"
   },
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def forward(self, query, key, value, mask = None):\n",
    "        key_tp = key.transpose(-2, -1)\n",
    "\n",
    "        scores = query.matmul(key_tp) / math.sqrt(query.size()[-1])\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n",
    "            \n",
    "        attention = F.softmax(scores, dim = -1)\n",
    "\n",
    "        return attention.matmul(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "G-sb6gd7L5bR"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 head_num,\n",
    "                 bias=True,\n",
    "                 activation=F.relu):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        if in_features % head_num != 0:\n",
    "            raise ValueError('`in_features`({}) should be divisible by \\\n",
    "                `head_num`({})'.format(in_features, head_num))\n",
    "        self.in_features = in_features\n",
    "        self.head_num = head_num\n",
    "        self.activation = activation\n",
    "        self.bias = bias\n",
    "        self.linear_q = nn.Linear(in_features, in_features, bias)\n",
    "        self.linear_k = nn.Linear(in_features, in_features, bias)\n",
    "        self.linear_v = nn.Linear(in_features, in_features, bias)\n",
    "        self.linear_o = nn.Linear(in_features, in_features, bias)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        q, k, v = self.linear_q(q), self.linear_k(k), self.linear_v(v)\n",
    "        if self.activation is not None:\n",
    "            q = self.activation(q)\n",
    "            k = self.activation(k)\n",
    "            v = self.activation(v)\n",
    "\n",
    "        q = self._reshape_to_batches(q)\n",
    "        k = self._reshape_to_batches(k)\n",
    "        v = self._reshape_to_batches(v)\n",
    "        \n",
    "        if mask is not None:\n",
    "            mask = mask.repeat(self.head_num, 1, 1)   \n",
    "        \n",
    "        y = ScaledDotProductAttention()(q, k, v, mask)        \n",
    "        \n",
    "        y = self._reshape_from_batches(y)      \n",
    "\n",
    "        y = self.linear_o(y)\n",
    "        if self.activation is not None:\n",
    "            y = self.activation(y)\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def gen_causal_mask(x):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        return torch.tril(torch.ones(seq_len, seq_len)).view(1, seq_len, seq_len).repeat(batch_size, 1, 1)\n",
    "\n",
    "    def _reshape_to_batches(self, x):\n",
    "        batch_size, seq_len, in_feature = x.size()\n",
    "        sub_dim = in_feature // self.head_num\n",
    "        return x.reshape(batch_size, seq_len, self.head_num, sub_dim)\\\n",
    "                .permute(0, 2, 1, 3)\\\n",
    "                .reshape(batch_size * self.head_num, seq_len, sub_dim)\n",
    "\n",
    "    def _reshape_from_batches(self, x):\n",
    "        batch_size, seq_len, in_feature = x.size()\n",
    "        batch_size //= self.head_num\n",
    "        out_dim = in_feature * self.head_num\n",
    "        return x.reshape(batch_size, self.head_num, seq_len, in_feature)\\\n",
    "                .permute(0, 2, 1, 3)\\\n",
    "                .reshape(batch_size, seq_len, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NDpTASiaTxTX"
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 embedding_dim: int,\n",
    "                 n_self_heads: int,\n",
    "                 n_features: int,\n",
    "                 n_layers: int,\n",
    "                 n_classes: int):\n",
    "        super().__init__()\n",
    "\n",
    "        #Embedding layer\n",
    "        self.embedding = nn.Embedding(n_features, embedding_dim)\n",
    "        #Positional encoding\n",
    "        self.pos_encode = PositionalEncoding(embedding_dim)\n",
    "\n",
    "        self.decoder_layers = []\n",
    "\n",
    "        for _ in range(n_layers):\n",
    "            layer = []\n",
    "            #Add multihead, which will be cross or self attention\n",
    "            layer.append(MultiHeadAttention(embedding_dim, n_self_heads)) #self attention first, masked\n",
    "            #Now add layer norm\n",
    "            layer.append(nn.LayerNorm(embedding_dim))\n",
    "            #Add a feed forward\n",
    "            layer.append(nn.Linear(embedding_dim, embedding_dim))\n",
    "            #Now add layer norm\n",
    "            layer.append(nn.LayerNorm(embedding_dim))\n",
    "\n",
    "            self.decoder_layers.append(nn.ModuleList(layer))\n",
    "        self.decoder_layers=nn.ModuleList(self.decoder_layers)\n",
    "\n",
    "        self.to_out = nn.Linear(embedding_dim, n_classes)\n",
    "            \n",
    "    def forward(self, x: torch.Tensor, calculate_loss: bool = False):\n",
    "        \"\"\"\n",
    "        Expect tensor of [batch_size, n_features]\n",
    "        \"\"\"\n",
    "        if calculate_loss:\n",
    "            #If give model that accepts ?x?x4 abcd, expect bcd0\n",
    "            \n",
    "            target_logits=torch.cat([x[:,1:], torch.zeros((x.shape[0],1)).to(device)], dim=-1) ## if x is abcd, then target_logits is bcd0\n",
    "\n",
    "        x=x.long().to(device)\n",
    "        embed = self.embedding(x)\n",
    "        pos_encode = self.pos_encode(embed)\n",
    "\n",
    "        res = embed+pos_encode\n",
    "        \n",
    "        for decoder_layer in self.decoder_layers:\n",
    "            d_self_attention = decoder_layer[0]\n",
    "            d_layer_norm_1 = decoder_layer[1]\n",
    "            d_ff = decoder_layer[2]\n",
    "            d_layer_norm_2 = decoder_layer[3]\n",
    "            \n",
    "            ## Run the decoder\n",
    "            #do masked self attention\n",
    "            mask = MultiHeadAttention.gen_causal_mask(res).to(device)\n",
    "            res = res + d_self_attention(res,res,res, mask = mask)\n",
    "            self_res = res\n",
    "            #layer norm\n",
    "            res = d_layer_norm_1(res)\n",
    "\n",
    "            #do ff\n",
    "            res = self_res + d_ff(res)\n",
    "            #layer norm\n",
    "            res = d_layer_norm_2(res)\n",
    "\n",
    "        out = self.to_out(res)\n",
    "        if calculate_loss:\n",
    "            loss = nn.functional.cross_entropy(out.permute(0, 2, 1), target_logits.long())\n",
    "            return out,loss\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HqGGEpvCLbP8"
   },
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, n_pad: int, device: torch.device, pad_byte: int = 0, split: str = \"\\n\"):\n",
    "        self.n_pad = n_pad\n",
    "        self.device = device\n",
    "        self.pad_byte = pad_byte\n",
    "        self.split = split\n",
    "\n",
    "    def tokenize_str(self, sentence: str, encoding = \"utf8\") -> torch.Tensor:\n",
    "        base = [int(i) for i in bytes(sentence, encoding)]\n",
    "        if len(base) < self.n_pad:\n",
    "            base.extend([self.pad_byte] * (self.n_pad - len(base)))\n",
    "        assert len(base) == self.n_pad, f\"n_pad is too small, use {len(base)} or greater.\"\n",
    "        tensor = torch.Tensor(base)\n",
    "        return tensor.to(self.device)\n",
    "\n",
    "    def texts_to_sequences(self, texts: typing.List[str], encoding = \"utf8\") -> torch.Tensor:\n",
    "        # tokenize the input text\n",
    "        sentences = []\n",
    "        for sentence in texts:\n",
    "            sentences.append(self.tokenize_str(sentence).unsqueeze(0))\n",
    "\n",
    "        return torch.cat(sentences, dim = 0).to(self.device)\n",
    "    \n",
    "    @staticmethod\n",
    "    def prepare_texts(document: str) -> typing.List[str]:\n",
    "        return filter(lambda x: len(x)!=0, document.split(self.split))\n",
    "    \n",
    "    def sequences_to_texts(self, texts: torch.Tensor, encoding = \"utf8\") -> typing.List[str]:\n",
    "        out = []\n",
    "        for seq in texts:\n",
    "            chars = []\n",
    "            i=0\n",
    "            while i<len(seq) and seq[i] != 0:\n",
    "                chars.append(int(seq[i]))\n",
    "                i+=1\n",
    "            out.append(bytes(chars).decode(encoding, \"replace\"))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "pB-Xcf4TkKNQ"
   },
   "outputs": [],
   "source": [
    "def generate(seed: str, cutoff: int = 1024) -> str:\n",
    "    output = torch.tensor([list(bytes(seed,\"utf8\"))]).to(device)\n",
    "    \n",
    "    res=output\n",
    "    last = -1\n",
    "    i=0\n",
    "    while last != 0 and i<cutoff:\n",
    "        res = model(output)\n",
    "        argmax=res.argmax(-1)\n",
    "        \n",
    "        out = list(output[0])\n",
    "        out.append(list(argmax.to(device)[0])[-1])\n",
    "        last = list(argmax.to(device)[0])[-1]\n",
    "        output = torch.tensor([out])\n",
    "        i+=1\n",
    "    \n",
    "    if last == 0:\n",
    "        return convert_to_str(output)\n",
    "    return convert_to_str(output)+\"<CUTOFF>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "R81mAag8mHEG"
   },
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data: typing.List[str], n_pad):\n",
    "        self.raw_data = data\n",
    "        self.tokenizer = Tokenizer(n_pad, device, split = \"\\0\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.raw_data)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return self.tokenizer.tokenize_str(self.raw_data[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xQidsLjVaFUi"
   },
   "outputs": [],
   "source": [
    "def convert_to_str(x: torch.Tensor) -> str:\n",
    "    #Expects [1, 256] tensor\n",
    "    bts = []\n",
    "    i=0\n",
    "    while len(bts)<x.shape[1] and x[0][i] != 0:\n",
    "        bts.append(int(x[0][i]))\n",
    "        i+=1\n",
    "    return bytes(bts).decode(\"utf8\",\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "97rbDfS4gO8C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head size: 10\n"
     ]
    }
   ],
   "source": [
    "n_features = 256 # No. of tokens\n",
    "n_pad = 512 # Max line length\n",
    "embedding_dim = 640\n",
    "batch_size = 48\n",
    "head_factor = 64\n",
    "assert embedding_dim%head_factor == 0\n",
    "head_size = embedding_dim//head_factor\n",
    "print(f\"Head size: {head_size}\")\n",
    "n_layers = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IvvenMeUKfaj",
    "outputId": "fb38b6f5-0eaf-4d89-83ad-bee41604b8ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187129\n"
     ]
    }
   ],
   "source": [
    "path_to_data = \"data/reddit_scrape_v8.txt\"\n",
    "data_raw = open(path_to_data, encoding=\"utf-8\").read()\n",
    "\n",
    "data_split = list(filter(lambda x: x!=\"\", data_raw.split(\"\\0\")))\n",
    "random.shuffle(data_split)\n",
    "\n",
    "train_data = data_split[100:]\n",
    "print(len(train_data))\n",
    "val_data = data_split[:100]\n",
    "\n",
    "train_dataloader = TextDataset(train_data, n_pad)\n",
    "test_dataloader = TextDataset(train_data, n_pad)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(train_dataloader, batch_size=batch_size)\n",
    "testloader = torch.utils.data.DataLoader(test_dataloader , batch_size=1)\n",
    "testloader_iter = iter(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "GvibftHanb0A"
   },
   "outputs": [],
   "source": [
    "model = Transformer(embedding_dim, head_size, n_features, n_layers, 256)\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29080576 trainable params\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(count_parameters(model), \"trainable params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PXqmUSK0M3hD",
    "outputId": "69ad8160-d138-4e98-99b6-bd8cb83753c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "torch.Size([1, 512, 256])\n"
     ]
    }
   ],
   "source": [
    "input=next(testloader_iter)\n",
    "input=input.to(device)\n",
    "print(input.shape)\n",
    "res = model(input)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "tZji9Va7-unn"
   },
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "hUN0DJQo-vmf"
   },
   "outputs": [],
   "source": [
    "n_epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GczR7J4u6L5Q",
    "outputId": "15259e58-4468-44ff-dcf3-6c8dfb86d6bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May  3 10:28:40 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A10          On   | 00000000:06:00.0 Off |                    0 |\n",
      "|  0%   67C    P0    68W / 150W |   1506MiB / 23028MiB |      3%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    920327      C   /usr/bin/python3                 1504MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "yYr65bmbITE1"
   },
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"Why does Earth orbit the Sun?\",\n",
    "    \"Hello world, \",\n",
    "    \"How to use ChatGPT?\",\n",
    "    \"My code does not work. What should I do?\",\n",
    "    \"Why is this code not working: `1+\\\"A\\\"`?\",\n",
    "    \"Why is Java better than Python?\",\n",
    "    \"Why is Python better than Java?\",\n",
    "    \"What is the purpose of the main() function in C?\",\n",
    "    \"What is coding?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o85FrKyF-wg-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3899/3899 [1:11:44<00:00,  1.10s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 0: Why does Earth orbit the Sun?\n",
      "Model output: Why does Earth orbit the Sun?\n",
      "I was there a start of the same that are and there are a stranger that the same the same that they are they are they are they are they are they are they are they are they are they are they are theyen they are they are they are they are they are theyen they are they are starage theyen they are they are starage theyen they are they are they are theyer are starage than they are they are they are than they aread than they and than they argstanage.\n",
      "\n",
      "Prompt 1: Hello world, \n",
      "Model output: Hello world, in strang stranger stranger than the same the same that as a stranger than a stranger than a start and a start and then algeed the same that are some there are some than they are and they are starage they are starage they are starage than and they are starage than a faily and a starage than a faily and there.\n",
      "They are stare they are they are they are they are they are they are they and they are they and they as thank.\n",
      "\n",
      "Prompt 2: How to use ChatGPT?\n",
      "Model output: How to use ChatGPT?\n",
      "There is a some a from the same that are and the same the same the same the same the same the same that they are they are they are they are they are they are they are they are they are they are they are they are they are theyen they are they are theyey are and they are theyen they are they are theyen theyey are they are theyey are starage than they are they are they are theyer are starage than they aread than they aread than that asken than they and than ave.\n",
      "\n",
      "Prompt 3: My code does not work. What should I do?\n",
      "Model output: My code does not work. What should I do?\n",
      "I do t so a start ayo there any are and the same the only the same or any the same the same or any everything the same they are they are they are they are they are they are they are they are they are they are theyen they are they are start theyen they are they are they are they are theyen theyen they are they are theyen theyen theyen are they are they are theyer and they are they and they aread than than they and they and than ave.\n",
      "\n",
      "Prompt 4: Why is this code not working: `1+\"A\"`?\n",
      "Model output: Why is this code not working: `1+\"A\"`?\n",
      "If you're never trying to the trick the the transport the transform the train the transform the transform the track the the track the the track the the transform the track the the track the the track the the transform the track the the track the the track the the track the the track the the track the the the they are the track the they they are they are they they and they they are they and they they and they they and they they and there.\n",
      "\n",
      "Prompt 5: Why is Java better than Python?\n",
      "Model output: Why is Java better than Python?\n",
      "I think there is a good an array and the same the same the same that the same the same the same the same that the same the same the same the same the standard the same the standard the start the start the start they are they are they are they are they are theyen they are they are they are theyen they are they are theyen they are they are they are they are they are they and they they aread than they and they and they as a thay aske.\n",
      "\n",
      "Prompt 6: Why is Python better than Java?\n",
      "Model output: Why is Python better than Java?\n",
      "I think your start the same the same that year and the same the same the same the same that the same the same the same the same that the same the same the same that they are they are they are they are they are they are they are they are they are theyen they are they are theyen they are they are they are they are theyen they are they are they area strial and they are they aread than they aread than they argstandacall than than they and and and and any a a sssstacacancance.\n",
      "\n",
      "Prompt 7: What is the purpose of the main() function in C?\n",
      "Model output: What is the purpose of the main() function in C?\n",
      "I have a started in the start of the start is a stranger that is a stranger than the same or a stranger that is a stranger that is a strain and then it is there are some the start there is a strain and there are strain there are stranger there are stranger the start there are strang there the transformal the transformation there and there there are straches trans the transer them.\n",
      "\n",
      "Prompt 8: What is coding?\n",
      "Model output: What is coding?\n",
      "There are year are some that the same the same the same the same the same the same the same that they are they are they are they are they are they are they are theyen they are they are they are they are they are they are theyen they are they are they are theyen they are they are theyen they are they are starage theyen they are they are theyen they are they are theyer are starage than they are they aread than they aread than they aread thans.\n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1089/3899 [19:52<51:18,  1.10s/it] "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "epoch_losses = []\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    \n",
    "    batch_losses = []\n",
    "    for data in tqdm.tqdm(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        data = data.to(device)\n",
    "\n",
    "        output, loss = model(data, True)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_losses.append(loss.item())\n",
    "\n",
    "        \n",
    "    epoch_losses.append(sum(batch_losses)/len(batch_losses))\n",
    "\n",
    "    plt.plot(range(len(batch_losses)),batch_losses)\n",
    "    plt.xlabel(\"Batch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Batch loss\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(range(len(epoch_losses)), epoch_losses)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Epoch loss\")\n",
    "    plt.show()\n",
    "\n",
    "    torch.save(model, prefix_models+f\"model_E{epoch}\")\n",
    "\n",
    "    with open(prefix_models+\"losses.txt\", \"a\") as f:\n",
    "        f.write(f\"{epoch_losses[-1]}\\n\")\n",
    "        \n",
    "    scheduler.step()    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, prompt in enumerate(prompts):\n",
    "            print(f\"Prompt {i}: {prompt}\")\n",
    "            output=generate(prompt)\n",
    "            print(f\"Model output: {output}\")\n",
    "            print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUracnfcZSLX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torch.load(prefix_models+\"model_E0\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, prompt in enumerate(prompts):\n",
    "        print(f\"Prompt {i}: {prompt}\")\n",
    "        output=generate(prompt)\n",
    "        print(f\"Model output: {output}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r31WSN9YiTuZ"
   },
   "outputs": [],
   "source": [
    "import builtins\n",
    "while True:\n",
    "    prompt = builtins.input(\">>> \")\n",
    "    output=generate(prompt)\n",
    "    print(f\"Model output: {output}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
