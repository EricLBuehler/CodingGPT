{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BHZnXywjxGeq"
   },
   "outputs": [],
   "source": [
    "#https://pytorch.org/tutorials/beginner/transformer_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kY_j8RUDP5y4"
   },
   "outputs": [],
   "source": [
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import math\n",
    "from torch.autograd.variable import Variable\n",
    "import typing\n",
    "import random\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "y4lRdOSZNpe2"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ph2WO5JpKukk",
    "outputId": "ab00d895-307a-4ade-e705-1c6dd8ae6926"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "modelname=\"4_26_23_m1\"\n",
    "\n",
    "prefix_models=\"models/\"+modelname+\"/\"\n",
    "\n",
    "if not os.path.exists(prefix_models):\n",
    "    os.makedirs(prefix_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Oe3wtt5oADl6"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xGOoJdNdRSaO"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        #mine is [batch, seq, embed]\n",
    "        x = x.permute((1,0,2))\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        dropout = self.dropout(x)\n",
    "        return dropout.permute((1,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XakHZ4HfFdYM"
   },
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def forward(self, query, key, value, mask = None):\n",
    "        key_tp = key.transpose(-2, -1)\n",
    "\n",
    "        scores = query.matmul(key_tp) / math.sqrt(query.size()[-1])\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n",
    "            \n",
    "        attention = F.softmax(scores, dim = -1)\n",
    "\n",
    "        return attention.matmul(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "G-sb6gd7L5bR"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 head_num,\n",
    "                 bias=True,\n",
    "                 activation=F.relu):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        if in_features % head_num != 0:\n",
    "            raise ValueError('`in_features`({}) should be divisible by \\\n",
    "                `head_num`({})'.format(in_features, head_num))\n",
    "        self.in_features = in_features\n",
    "        self.head_num = head_num\n",
    "        self.activation = activation\n",
    "        self.bias = bias\n",
    "        self.linear_q = nn.Linear(in_features, in_features, bias)\n",
    "        self.linear_k = nn.Linear(in_features, in_features, bias)\n",
    "        self.linear_v = nn.Linear(in_features, in_features, bias)\n",
    "        self.linear_o = nn.Linear(in_features, in_features, bias)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        q, k, v = self.linear_q(q), self.linear_k(k), self.linear_v(v)\n",
    "        if self.activation is not None:\n",
    "            q = self.activation(q)\n",
    "            k = self.activation(k)\n",
    "            v = self.activation(v)\n",
    "\n",
    "        q = self._reshape_to_batches(q)\n",
    "        k = self._reshape_to_batches(k)\n",
    "        v = self._reshape_to_batches(v)\n",
    "        \n",
    "        if mask is not None:\n",
    "            mask = mask.repeat(self.head_num, 1, 1)   \n",
    "        \n",
    "        y = ScaledDotProductAttention()(q, k, v, mask)        \n",
    "        \n",
    "        y = self._reshape_from_batches(y)      \n",
    "\n",
    "        y = self.linear_o(y)\n",
    "        if self.activation is not None:\n",
    "            y = self.activation(y)\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def gen_causal_mask(x):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        return torch.tril(torch.ones(seq_len, seq_len)).view(1, seq_len, seq_len).repeat(batch_size, 1, 1)\n",
    "\n",
    "    def _reshape_to_batches(self, x):\n",
    "        batch_size, seq_len, in_feature = x.size()\n",
    "        sub_dim = in_feature // self.head_num\n",
    "        return x.reshape(batch_size, seq_len, self.head_num, sub_dim)\\\n",
    "                .permute(0, 2, 1, 3)\\\n",
    "                .reshape(batch_size * self.head_num, seq_len, sub_dim)\n",
    "\n",
    "    def _reshape_from_batches(self, x):\n",
    "        batch_size, seq_len, in_feature = x.size()\n",
    "        batch_size //= self.head_num\n",
    "        out_dim = in_feature * self.head_num\n",
    "        return x.reshape(batch_size, self.head_num, seq_len, in_feature)\\\n",
    "                .permute(0, 2, 1, 3)\\\n",
    "                .reshape(batch_size, seq_len, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NDpTASiaTxTX"
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 embedding_dim: int,\n",
    "                 n_self_heads: int,\n",
    "                 n_features: int,\n",
    "                 n_layers: int,\n",
    "                 n_classes: int):\n",
    "        super().__init__()\n",
    "\n",
    "        #Embedding layer\n",
    "        self.embedding = nn.Embedding(n_features, embedding_dim)\n",
    "        #Positional encoding\n",
    "        self.pos_encode = PositionalEncoding(embedding_dim)\n",
    "\n",
    "        self.decoder_layers = []\n",
    "\n",
    "        for _ in range(n_layers):\n",
    "            layer = []\n",
    "            #Add multihead, which will be cross or self attention\n",
    "            layer.append(MultiHeadAttention(embedding_dim, n_self_heads)) #self attention first, masked\n",
    "            #Now add layer norm\n",
    "            layer.append(nn.LayerNorm(embedding_dim))\n",
    "            #Add a feed forward\n",
    "            layer.append(nn.Linear(embedding_dim, embedding_dim))\n",
    "            #Now add layer norm\n",
    "            layer.append(nn.LayerNorm(embedding_dim))\n",
    "\n",
    "            self.decoder_layers.append(nn.ModuleList(layer))\n",
    "        self.decoder_layers=nn.ModuleList(self.decoder_layers)\n",
    "\n",
    "        self.to_out = nn.Linear(embedding_dim, n_classes)\n",
    "            \n",
    "    def forward(self, x: torch.Tensor, calculate_loss: bool = False):\n",
    "        \"\"\"\n",
    "        Expect tensor of [batch_size, n_features]\n",
    "        \"\"\"\n",
    "        if calculate_loss:\n",
    "            #If give model that accepts ?x?x4 abcd, expect bcd0\n",
    "            \n",
    "            target_logits=torch.cat([x[:,1:], torch.zeros((x.shape[0],1)).to(device)], dim=-1) ## if x is abcd, then target_logits is bcd0\n",
    "\n",
    "        x=x.long().to(device)\n",
    "        embed = self.embedding(x)\n",
    "        pos_encode = self.pos_encode(embed)\n",
    "\n",
    "        res = embed+pos_encode\n",
    "        \n",
    "        for decoder_layer in self.decoder_layers:\n",
    "            d_self_attention = decoder_layer[0]\n",
    "            d_layer_norm_1 = decoder_layer[1]\n",
    "            d_ff = decoder_layer[2]\n",
    "            d_layer_norm_2 = decoder_layer[3]\n",
    "            \n",
    "            ## Run the decoder\n",
    "            #do masked self attention\n",
    "            mask = MultiHeadAttention.gen_causal_mask(res).to(device)\n",
    "            res = res + d_self_attention(res,res,res, mask = mask)\n",
    "            self_res = res\n",
    "            #layer norm\n",
    "            res = d_layer_norm_1(res)\n",
    "\n",
    "            #do ff\n",
    "            res = self_res + d_ff(res)\n",
    "            #layer norm\n",
    "            res = d_layer_norm_2(res)\n",
    "\n",
    "        out = self.to_out(res)\n",
    "        if calculate_loss:\n",
    "            loss = nn.functional.cross_entropy(out.permute(0, 2, 1), target_logits.long())\n",
    "            return out,loss\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HqGGEpvCLbP8"
   },
   "outputs": [],
   "source": [
    "def tokenize_multi(text_seq: str, features: int, encoding = \"utf8\") -> torch.Tensor:\n",
    "    # tokenize the input text\n",
    "    sentences = []\n",
    "    for sentence in filter(lambda x: x!=\"\", text_seq.split(\"\\n\")):\n",
    "        base = list(bytes(sentence, \"utf8\"))\n",
    "        if len(base) < features:\n",
    "            base.extend([0] * (features - len(base)))\n",
    "        tensor = torch.Tensor(base)\n",
    "        tensor = tensor.unsqueeze(0)\n",
    "        sentences.append(tensor)\n",
    "\n",
    "    return torch.cat(sentences, dim = 0)\n",
    "\n",
    "def tokenize_single(sentence: str, features: int, encoding = \"utf8\") -> torch.Tensor:\n",
    "    base = list(bytes(sentence, \"utf8\"))\n",
    "    if len(base) < features:\n",
    "        base.extend([0] * (features - len(base)))\n",
    "    tensor = torch.Tensor(base)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "pB-Xcf4TkKNQ"
   },
   "outputs": [],
   "source": [
    "def generate(seed: str, cutoff: int = 1024) -> str:\n",
    "    output = torch.tensor([list(bytes(seed,\"utf8\"))]).to(device)\n",
    "    \n",
    "    res=output\n",
    "    last = -1\n",
    "    i=0\n",
    "    while last != 0 and i<cutoff:\n",
    "        res = model(output)\n",
    "        argmax=res.argmax(-1)\n",
    "        \n",
    "        out = list(output[0])\n",
    "        out.append(list(argmax.to(device)[0])[-1])\n",
    "        last = list(argmax.to(device)[0])[-1]\n",
    "        output = torch.tensor([out])\n",
    "        i+=1\n",
    "    \n",
    "    if last == 0:\n",
    "        return convert_to_str(output)\n",
    "    return convert_to_str(output)+\"<CUTOFF>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "R81mAag8mHEG"
   },
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data: typing.List[str], features):\n",
    "        self.raw_data = data\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.raw_data)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return tokenize_single(self.raw_data[index], self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xQidsLjVaFUi"
   },
   "outputs": [],
   "source": [
    "def convert_to_str(x: torch.Tensor) -> str:\n",
    "    #Expects [1, 256] tensor\n",
    "    bts = []\n",
    "    i=0\n",
    "    while len(bts)<x.shape[1] and x[0][i] != 0:\n",
    "        bts.append(int(x[0][i]))\n",
    "        i+=1\n",
    "    return bytes(bts).decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "97rbDfS4gO8C"
   },
   "outputs": [],
   "source": [
    "n_features = 256 # No. of tokens\n",
    "n_pad = 1024 # Max line length\n",
    "embedding_dim = 384\n",
    "batch_size = 16\n",
    "head_factor = 64\n",
    "assert embedding_dim%head_factor == 0\n",
    "head_size = embedding_dim//head_factor\n",
    "n_layers = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IvvenMeUKfaj",
    "outputId": "fb38b6f5-0eaf-4d89-83ad-bee41604b8ef"
   },
   "outputs": [],
   "source": [
    "path_to_data = \"data/reddit_scrape.txt\"\n",
    "data_raw = open(path_to_data, encoding=\"utf-8\").read()\n",
    "\n",
    "data_split = list(filter(lambda x: x!=\"\", data_raw.split(\"\\n\")))\n",
    "random.shuffle(data_split)\n",
    "\n",
    "train_data = data_split[100:]\n",
    "val_data = data_split[:100]\n",
    "\n",
    "train_dataloader = TextDataset(train_data, n_pad)\n",
    "test_dataloader = TextDataset(train_data, n_pad)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(train_dataloader, batch_size=batch_size)\n",
    "testloader = torch.utils.data.DataLoader(test_dataloader , batch_size=1)\n",
    "testloader_iter = iter(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "GvibftHanb0A"
   },
   "outputs": [],
   "source": [
    "model = Transformer(embedding_dim, head_size, n_features, n_layers, 256)\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PXqmUSK0M3hD",
    "outputId": "69ad8160-d138-4e98-99b6-bd8cb83753c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024])\n",
      "torch.Size([1, 1024, 256])\n",
      "tensor([[  3, 117, 104,  ...,  53,  53,  53]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "input=next(testloader_iter)\n",
    "input=input.to(device)\n",
    "res = model(input)\n",
    "print(input.shape)\n",
    "print(res.shape)\n",
    "print(res.argmax(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "tZji9Va7-unn"
   },
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "hUN0DJQo-vmf"
   },
   "outputs": [],
   "source": [
    "n_epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GczR7J4u6L5Q",
    "outputId": "15259e58-4468-44ff-dcf3-6c8dfb86d6bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 26 12:15:32 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A10          On   | 00000000:06:00.0 Off |                    0 |\n",
      "|  0%   48C    P0    62W / 150W |   1855MiB / 23028MiB |      3%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     66345      C   /usr/bin/python3                 1853MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "yYr65bmbITE1"
   },
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"Why does Earth orbit the Sun?\",\n",
    "    \"How to use ChatGPT?\",\n",
    "    \"My code does not work. What should I do?\",\n",
    "    \"Why is this code not working: `1+\\\"A\\\"`?\",\n",
    "    \"Why is Java better than Python?\",\n",
    "    \"Why is Python better than Java?\",\n",
    "    \"What is the purpose of the main() function in C?\",\n",
    "    \"What is coding?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o85FrKyF-wg-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8060/8060 [1:42:56<00:00,  1.30it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjK0lEQVR4nO3dd3yV9fn/8ddFwgxLICCCLHEUEZEiS+oeKK621lGtWrXWtlrb/jq0atWvtVptrbXaqrWuVq39ur4UHDhABRQIe8sKewQCCYTsXL8/7jvxHE4CYRzOyc37+Xjkkfvc8+Lk5n3u8/ncw9wdERGJnkapLkBERJJDAS8iElEKeBGRiFLAi4hElAJeRCSiFPAiIhGlgBepg5nlmtmZ9Zz3WjObkOyaRPaEAl4alDB0i81su5ltMbMxZnZ4PZftYWZuZpnJrlMkHSjgpSG6wN1bAp2BDcBfUlyPSFpSwEuD5e4lwGtAn+pxZjbSzGaYWaGZrTKze2IW+ST8vTX8BjA0XOZ7ZrbAzLaZ2XwzGxCzTH8zm21mBWb2qpk1q09tZjbMzKaGy001s2Ex0641s2Xh9pab2ZXh+N5m9nG4zCYze3Xv3hmRgAJeGiwzawFcBnweM7oIuBpoC4wEfmBmF4fTTg5/t3X3lu7+mZl9C7gnXKY1cCGwOWZ9lwIjgJ5AP+DaetTVDhgDPAa0Bx4BxphZezPLCsef6+6tgGHAzHDR+4CxwCFAV/TNRPaRAl4aorfMbCtQAJwFPFw9wd3Hu/scd69y99nAK8Apu1jXDcBD7j7VA0vcfUXM9Mfcfa275wP/BfrXo76RwGJ3/6e7V7j7K8BC4IJwehXQ18yau/s6d58Xji8HugOHuXuJu6vTVvaJAl4aoovdvS3QDLgZ+NjMDgUws8FmNs7M8sysALgJ6LCLdR0OLN3F9PUxwzuAlvWo7zBgxU7jVgBd3L2I4FvHTcC6sJP4mHCeXwIGTDGzeWZ2XT22JVInBbw0WO5e6e5vAJXA8HD0y8Ao4HB3bwM8SRCaALXdOnUVcMR+Lm0twZF4rG7AmrDu99z9LIJO4oXA38Px6939e+5+GPB94K9m1ns/1yYHEQW8NFgWuIigzXpBOLoVkO/uJWY2CPh2zCJ5BM0jvWLGPQP83My+Gq6vt5ntHM576m3gKDP7tpllmtllBB3Bo82sk5ldFLbFlwLbw5ows2+ZWddwHVsIPpCq9rEWOYjpfGBpiP5rZpUEAbgCuCamHfuHwB/N7HHgY+A/BB2uuPsOM7sfmGhmjYER7v6/Ztae4Mi/C5ALfIfEJpZ6c/fNZnY+8Gfgb8AS4Hx332RmnYGfAS+G9c8EfhAueiLwqJm1ITj981Z3X7a3dYiYHvghIhJNaqIREYkoBbyISEQp4EVEIkoBLyISUWl1Fk2HDh28R48eqS5DRKTBmDZt2iZ3z65tWloFfI8ePcjJyUl1GSIiDYaZ1XlKr5poREQiSgEvIhJRCngRkYhSwIuIRJQCXkQkohTwIiIRpYAXEYmoSAT8Xz5czMdf5KW6DBGRtBKJgP/r+KVMXLIp1WWIiKSVSAS8iIgkUsCLiESUAl5EJKIiE/B69KCISLxIBLxZqisQEUk/kQh4ERFJpIAXEYmoyAS8muBFROJFIuDVBC8ikigSAS8iIokU8CIiEaWAFxGJqMgEvPpYRUTiRSLgTVc6iYgkiETAi4hIIgW8iEhEKeBFRCIqM5krN7NcYBtQCVS4+8BkbUtXsoqIxEtqwIdOc/ekPk9PXawiIonURCMiElHJDngHxprZNDO7McnbEhGRGMluohnu7mvMrCPwvpktdPdPYmcIg/9GgG7duu31hlyXOomIxEnqEby7rwl/bwTeBAbVMs/T7j7Q3QdmZ2fv3YbUCC8ikiBpAW9mWWbWqnoYOBuYm6ztiYhIvGQ20XQC3gxvI5AJvOzu7yZxeyIiEiNpAe/uy4Djk7V+ERHZtcicJqkLnURE4kUi4NXHKiKSKBIBLyIiiRTwIiIRpYAXEYkoBbyISERFIuD1yD4RkUSRCHgREUmkgBcRiSgFvIhIREUm4F2XsoqIxIlEwKuPVUQkUSQCXkREEingRUQiKjIBrxZ4EZF4kQh4NcGLiCSKRMCLiEgiBbyISEQp4EVEIioyAa/rnERE4kUi4HU3SRGRRJEIeBERSaSAFxGJKAW8iEhERSbgXdeyiojEiUTAq4tVRCRRJAJeREQSJT3gzSzDzGaY2ehkb0tERL50II7gbwUWJHsjutBJRCReUgPezLoCI4FnkrudZK5dRKRhSvYR/KPAL4GqumYwsxvNLMfMcvLy8pJcjojIwSNpAW9m5wMb3X3aruZz96fdfaC7D8zOzk5WOSIiB51kHsGfBFxoZrnAv4HTzexfSdyeiIjESFrAu/vt7t7V3XsAlwMfuftVSdteslYsItJAReQ8ePWyiojsLPNAbMTdxwPjD8S2REQkEJEjeBER2ZkCXkQkoiIT8LqSVUQkXiQCXleyiogkikTAi4hIIgW8iEhERSjg1QgvIhIrEgGvJngRkUSRCHgREUmkgBcRiSgFvIhIREUm4HWhk4hIvEgEvC50EhFJFImAFxGRRAp4EZGIUsCLiERUZAJenawiIvEiEfCma1lFRBJEIuBFRCSRAl5EJKIiE/Cuu0mKiMSJRMDrQicRkUSRCHgREUmkgBcRiSgFvIhIREUm4HWhk4hIvEgEvPpYRUQSJS3gzayZmU0xs1lmNs/M7k3WtkREJFG9At7MssysUTh8lJldaGaNd7NYKXC6ux8P9AdGmNmQfapWRETqrb5H8J8AzcysCzAW+A7w/K4W8MD28GXj8Ect5SIiB0h9A97cfQfwDeCv7v4t4NjdLmSWYWYzgY3A++4+uZZ5bjSzHDPLycvL24PS4+mTQ0QkXr0D3syGAlcCY8JxGbtbyN0r3b0/0BUYZGZ9a5nnaXcf6O4Ds7Oz61lOQnF7tZyISJTVN+B/AtwOvOnu88ysFzCuvhtx963h/CP2tEAREdk7mfWZyd0/Bj4GCDtbN7n7j3e1jJllA+XuvtXMmgNnAb/fx3pFRKSe6nsWzctm1trMsoC5wHwz+8VuFusMjDOz2cBUgjb40ftWroiI1Fe9juCBPu5eaGZXAu8AtwHTgIfrWsDdZwMn7HuJ9aMrWUVE4tW3Db5xeN77xcAody9HJ66IiKS1+gb8U0AukAV8YmbdgcJkFSUiIvuuvp2sjwGPxYxaYWanJackERHZH+rbydrGzB6pviDJzP5IcDSfNvTIPhGRePVtonkW2AZcGv4UAs8lq6g9peucREQS1fcsmiPc/Zsxr+8Nb0EgIiJpqr5H8MVmNrz6hZmdBBQnpyQREdkf6nsEfxPwopm1CV9vAa5JTkkiIrI/1PcsmlnA8WbWOnxdaGY/AWYnsbY9oz5WEZE4e/REJ3cvdPfq899/loR69oo6WUVEEu3LI/sUqyIiaWxfAl6NIiIiaWyXbfBmto3ag9yA5kmpSERE9otdBry7tzpQhewrfZ0QEYm3L000acPUHSAikiASAS8iIokU8CIiERWZgHc90klEJE4kAl4XOomIJIpEwIuISCIFvIhIRCngRUQiKjIBry5WEZF4kQh49bGKiCSKRMCLiEgiBbyISEQp4EVEIippAW9mh5vZODObb2bzzOzWZG0LQBeyiojEq+9Dt/dGBfD/3H26mbUCppnZ++4+f39vyHQpq4hIgqQdwbv7OnefHg5vAxYAXZK1PRERiXdA2uDNrAdwAjC5lmk3mlmOmeXk5eUdiHJERA4KSQ94M2sJvA78xN0Ld57u7k+7+0B3H5idnb3X21ETvIhIvKQGvJk1Jgj3l9z9jaRtJ1krFhFpwJJ5Fo0B/wAWuPsjydqOiIjULplH8CcB3wFON7OZ4c95SdyeiIjESNppku4+AbWeiIikTGSuZNUj+0RE4kUj4PU9QUQkQTQCXkREEijgRUQiSgEvIhJRkQl4dbGKiMSLRMCrj1VEJFEkAl5ERBIp4EVEIio6Aa9GeBGROJEIeD3RSUQkUSQCXkREEingRUQiSgEvIhJRkQl4Vy+riEicSAS8ulhFRBJFIuBFRCSRAl5EJKIU8CIiERWZgNcT+0RE4kUi4HUhq4hIokgEvIiIJFLAi4hElAJeRCSiIhPw6mQVEYkXiYA3XcsqIpIgEgEvIiKJkhbwZvasmW00s7nJ2oaIiNQtmUfwzwMjkrj+OLqbpIhIvKQFvLt/AuQna/2xdKGTiEiilLfBm9mNZpZjZjl5eXl7tY4dZZUUFJfv58pERBq2lAe8uz/t7gPdfWB2dvZerWNl/g4+X3ZAviyIiDQYKQ94ERFJDgW8iEhEJfM0yVeAz4CjzWy1mV2frG2JiEiizGSt2N2vSNa6RURk99REIyISUQp4EZGIUsCLiESUAl5EJKIU8CIiERWpgHc99UNEpEakAn7OmgKKyypTXYaISFpI2nnwqXDh4xMByH1wZIorERFJvUgdwVf7aOGGvVpuzuoC/jp+yX6uRkQkNSIZ8Nc9n1MzPG7hRtYVFNdruQsen8BD7y5KVlkiIgdUJAO+2hcbtvHd56dy/mMTap2+dmsxX73vfZblbd+j9a7K30GP28Ywf23h/ihTRCQpIh3wZ//pEwA2F5XVOn307LVsLirj5ckr92i9Y+cHTUD/yVlVM87d6/ymMGHxJt6asabWae7OC5Ny2VaS+MCSd+as49PFe/4QlIrKKjZtL93j5UQkWiLVyRpr6U5H5T1uGwPAqzcO4bKnP4+b9syE5dx5fp+a10+MW8KQXu2ZsHgTI/oeytGHtgKgqsqZv66QeWsLgPhHBT47MZf7Rs8H4D/fH8qgnu0AWLl5B1f9YzIA3dq3oLLKObFHu5rlPlu2mbtHzWPmqq386bL+cXX94KXpwJ53Gv/P6Pm8+NkK5t57Di2bpvZP7O6MmbOOs/scSpPMSB9PiKSdyP6PO+OPH9c6fudwrzZxyaaa4YffW8Q3/zaJP33wBec8+gkl5ZU8/clSev36bc7/ywTemB4cjVefdp+Tm8/o2Wtrlr/0qc/YuK0EgEUbttWM/8ZfJ/GtJz/jg/kb6HHbGBZv2EZpeRUAizduY/7aQu4ZNY+i0oq42p75dBmr8neweMM2fvf2Ah54Z8Euz/l/b956ALaXVNQ5z77aUFjCdc9PrfWbR6xPF2/i5pdn8Iexe963ce1zU7hn1Ly9LVHkoBfZI/g9deUzk+uc9vB7i/jHhOUJ45+flMvzk3JrXWbQ/R9y38V9ueutuQnTbngx6AS++ImJjOjbGYC5awo577FPARg7bz2/ueDYmvl/O2YBvx2zALMvP1SOPawNR3dqxYrNRZx97KFx699QGDTPVMV8CMxctZU5awr4zpDuAJRVVJG3vZSWTTO55tkpHNelDfdd3BeAyirnrRlruPiELmQ0qv2J5n/+cDEfLdzIWzPX1qyzNlvDZ+Wu2Ro0Xy1cX0jPDlk0zcyoc5lq4xflAXncc+GxvDR5BXe8OZfbzz2G759yxG6XrU1llVNWUUXzJrvftkgURCLgrxzcjZf2sB19T9QW7vVRW7jHKiqr5PXpqxPGry0o4aZ/TUsYH3vQ/uNXZtQMt2yaydVDu9OzQxbfGNC1ZnxswF/8RHCNwLK87VwxqBtPfryUN6av4ehOrVi0YRszV22tCfiXJ6/grv+bx7qCYr49uDvtsprE1VFRWVXTb3HXW3PrDPjqUA6Kh42FJYx4NPgQm/LrM3h9+hrytpVy06m9mLWqgLP6dKp1PZOWbKpZzwPvLIwL+JzcfCqqnH5d2zBleT5NMhoxrHeHuOU/XZzHzS/PYPiRHRgze11ck9f0lVtYtH4bVwzqVuu2U2l9QQkdWzWlUR0fsg1BSXklzRrrAzVVLJ0u7x84cKDn5OTsfsadVFU5vX79dhIqaviuGNSNXh2yuP/tBbudtzr4Trz/A/K2fdlJO+WOM7jhhRyO7NiKn59zFKf9YTwlYdMSwPn9OnPPhceyKn8HyzcV8fr01Uxcsjlu3ef2PZS2LZrwypTED+Je2VksyyviiW8P4PB2zenXtS3wZb/JY1ecEPeBNqhHO/546fEc3q5FzTztspqQH3am5z44kjVbi/nVa7N57rsncuQd78Rtb/kD52FmlFZUcvSd78b926uqnK3F5QkfamUVVTzwzgI+XLCRT3552m7fS3dn1Ky1nH5MR8YtyuPsPp14c8YaLj/xcCym82ZbSTnvzF3PJQO6csdbcygtr+KRy/rz6tSV/Or1OYw8rjNPXDmgzu1UVTkPj13EVUO606Vt893WtacuenwCBcXljP/F7v/NO5uyPJ9Ln/qMl24YzEk7fejK/mNm09x9YG3TInEEbw33ACfpagvUuhx393u0bJYZF+4QNDcBzF5dUOs3jtGz1zF69rpdrvuduevrnLYsrwiAH708vWbcw5f0qxne+SBkSm4+1zw7hfd+enLNuPyYM6UeeHsBT32yDIB/fb4iYXs7yip55P0vEr6ZVVU5Z/7pY5blFfH3qwfyvRdz+P4pvejUqhn/E3agA/S8fQz/un4wR3ZqSUlZFb9/dyGPXHY8TTMzWF9QQrusJnywYAO3/ntmwraXbtxe06FfWlHJLa/MYPyiPJ6dsJyF64P+mkcu689zE3MBGDNnHU/stI5Pvshj2BHtycxoxKSlm/nb+KVMXZ7Paz8YlrC9WNNW5NO7YyvaNG/MxsISlm0qYkiv9rtcZtbq4ISCHreN4YvfnsvW4jI6tmoGQGFJOa9MXskVg7vRulljbvrnNN6dt77mw3LysuBDftLSTTUBP2vVVsYvyuPWM4+sc5ulFZWMW5jHiL5fNj1uKymntKKKDi2b4u7kbSulY+tmu6wdghMmDm3djG9+tWud85RVVJHRyOpsjtwTZRVV/PK1WfzmgmMTDhJq89LkFdw7aj5z7z0nKSchROIIHr482hM5kFo2zWR7aQV/v3ogExbn8cJniR8oOzv16Oywf6F2z3/3RK59bmrcuDd/OIwmmY3ILyrjO/+YUutyQ3q14983DqWsooqN20roekgLLnpiIgU7yjj16I48PymXI7Kz+NWIY7jtjTnkF5WR++BIVm/ZQUl5FesKimnWOINDWjRm/KI8npuYW9N3AnD98J78Y8JyHvpmP1bm7+DxccFV3+2zmjDtrrNq/g/mPjiSuWsKePyjJbw7bz0/Ou0IfnHOMTzy/hc89uFiAF6+YTDDenegvLKKxhmNKCmvZM3WYlo2zeT6F6Yyd01h3Nlo/f9nLFt3lJP74Eju/e88npuYy9VDu7OhsIS7LziWw9o2Jyc3n8Ubt3P5iYezYvMOXpu2uqbG0bcMp3fHlqzK38GRnVrFvW89bhvD4J7tePX7QykprySzkVFQXM5Xf/sBw3t34F83DAaCpsnLn/6c/KIy3gj/HmUVVUxaupmNhSVcPbQHJ97/Qc1p2XPuOZtWzRrXbKe6yfYbA7pwXJc2ZGY0qnnPxv38VHp2yKpzn9iVXR3BK+BF9oPjurRhzpqCVJeRFu447ysJTYK19ZNVfzjefUEf7v3vfHb2h28dT7d2LWjRJIPz/1L7xYrVbjm9N3/5KAjzG4b35Jl69ps9ell/fvLqzITxvxxx9G6vaq+uf1dO6t2eYUd0oOshzRO+0f324r7cGYb+Q5f049KBh9er5p0p4EVE0tze3iQx8m3wAP26tgFgY2Ep6wtLUlyNiEjqRSbgR908HAg65N6bt4GZq7by5MdLa6Z/7cgOfLp4U12Li4hETuSuZDUzRvQ9lNvOPYblD5xXM/6f1w+uGZ5yxxl89P9O4YXrBtW6jge+cVyt4w+tR6+9iEi6iFzAx7Kdzp/MfXAkuQ+OpGOrZvTKbskpR2Xz/k9P5sXrBvG1I4PTuF64bhBXDOrGzN+cRe6DI1ly/7ncfu4xjPv5qbzxw2FcOrArlw08nGuH9ahZ7/e+1hMIzs9u07wxu/LIpccz+ddnMPqW4fRo36Jm/NdP6BI33yXhaV19OrcGiNvezh6+pB83n9Y77jzoXc3/UMwpiLvy4zPqPpVNRNJfZDpZ6/L2nHX0aJ9Fn8Na73K+SUs38e2/T2bGXWdxSD3OXwX4fNlmWjXL5NjD2rClqIw2zRvTqJGxpaiMWau3ckR2S/49dSUzVm7l5e8NSVje3Zm1uoC8baWc+ZWOQHBO+Yi+h9I4I/jsLS6r5LVpq7hqSPeED6xbXpmBEVwIBLClqIz56wrp17VN3OlZC9YV8tC7C/nuST3J21bKN7/alaoqZ/wXG+nYqhl3vjWXmau2MvqW4Rwbvk/u0KiR8cS4JfTskMWZX+lEaUUlx90zluO7tuH/bh5ecydMM+Pune4Zk/vgSLYUlXHCfe/zyKXH85XOrckvKuNP739BzootwJc3ZXti3BLenrOOeeHtl398em8yMxrxzKfLKNzN/XR+fMaRtGiSwenHdGTe2gJ++uqsmmm1nc3RrHGjuIu0YuXceSZXPP05W4vLuXJwNx79YPEuty2yPyWjkzWpAW9mI4A/AxnAM+7+4K7mT0bAy/5VfZ5wZkajhPFllVW4Q1aTjITpsbbuKKOsoiruQhV3Z21BSa1XY64rKOa21+dw1ZDudG7TjM+WbuaC4w9j9ZYdDIy5M2e18soqKqu85hL5qirn7lHzuPP8r9A0MwN3Z8uOcopKK8hu1ZSXJq/k4v6H0b5l07j1VFY5m4tKqah0xi/K49dvzuHNHw6jXVYT/j11Fd8c0IXPl+WzYnMRY2avo89hrfnLFQNo1AhW5RfzwqRcTj4qu+YWDEs2bmfz9lJ6ZbekZdNMVuQXce2zU/nvLcMpKC7jzEc+4a0fnUT/w9sC8Mb01XRvn0W/rm2orHLcgw+oCUs21ZwLv/C+EbwxfQ3vzF3H775+HFNz8+nUuhnbSys45ahsPlywkZOP6sBx94wFvgyRyiono5GxYF0hzRtn0KNDFhc9MZFZq7aSc+eZ5BeVcVSnVixYV8i5fw5uL3HX+X046yudOPnhcQDMuOssKsL36OmPl3Hd8J6Mnbeebu2z6NO5NZu2l3JS7w4cf+9YtpdWMPWOM8lu1ZTHPlxMYXF53KmMXdo255XvDeGwts14ZsJyHv9oSc0piLPvOZsH3l7AO3PXM/WOM7n0qc/4Wu8ODD2iAyvzi+jcpjlXPzuFbwzowq1nHEm3di14Y/oasppmctO/ptGvaxuymmSyaXsp20sr6NO5NaccnU3bFk04u08nTn14PL+9uC//yVlVcyvwf14/iN+/u5CrBndncK/2/Ow/M3nphsF8ungT3//nl7cR6dUhi2WbihL2wR7tW5C7eQddD2nO6z8YxuDffVjr/4UnrxrA85Nyuf/rx3FEdsta59mdlAS8mWUAXwBnAauBqcAV7p54wmtIAS/pyt1ZvaWYw9u12P3MB8Br01bT9ZDmu70StdrSvO0Ul1XSt0ubOucpKa+kpLySti3iv8G+OnUlQ3t1oFvYpLhicxEdWzXb55u2VVY5C9YV1llTYUk520oq9ukWDIvWb+OoTi0Tvv3WprisktVbEi+E2h9KyisBaNY4g4Licl6YlMuPTuu9X66eTVXADwXucfdzwte3A7j7A3Uto4AXEdkzuwr4ZHaydgFWxbxeHY6LY2Y3mlmOmeXk5e3504tERKR2KT+Lxt2fdveB7j4wOzs71eWIiERGMgN+DRB7c4Wu4TgRETkAkhnwU4EjzaynmTUBLgdGJXF7IiISI2m3KnD3CjO7GXiP4DTJZ91dD9gUETlAknovGnd/G9CjlkREUiDlnawiIpIcCngRkYhKq3vRmFkesPtnntWuA5CO9wNOx7rSsSZQXXsqHetKx5og2nV1d/dazzFPq4DfF2aWU9fVXKmUjnWlY02guvZUOtaVjjXBwVuXmmhERCJKAS8iElFRCvinU11AHdKxrnSsCVTXnkrHutKxJjhI64pMG7yIiMSL0hG8iIjEUMCLiERUgw94MxthZovMbImZ3XYAtvesmW00s7kx49qZ2ftmtjj8fUg43szssbC22WY2IGaZa8L5F5vZNfuhrsPNbJyZzTezeWZ2a6prM7NmZjbFzGaFNd0bju9pZpPDbb8a3owOM2savl4STu8Rs67bw/GLzOycva1pp/oyzGyGmY1Ol7rMLNfM5pjZTDPLCcelw/7V1sxeM7OFZrbAzIameN86OnyPqn8KzewnafJe/TTc3+ea2Svh/4PU7Fvu3mB/CG5ithToBTQBZgF9krzNk4EBwNyYcQ8Bt4XDtwG/D4fPA94BDBgCTA7HtwOWhb8PCYcP2ce6OgMDwuFWBI9L7JPK2sJ1twyHGwOTw239B7g8HP8k8INw+IfAk+Hw5cCr4XCf8G/bFOgZ/s0z9sPf8mfAy8Do8HXK6wJygQ47jUuH/esF4IZwuAnQNh3qCtebAawHuqe6JoKHGi0HmsfsU9emat/aL6GXqh9gKPBezOvbgdsPwHZ7EB/wi4DO4XBnYFE4/BTBc2jj5gOuAJ6KGR83336q8f8InoebFrUBLYDpwGCCK/cyd/4bEtx5dGg4nBnOZzv/XWPn24d6ugIfAqcDo8PtpENduSQGfEr/hkAbgtCydKorZj1nAxPToSa+fJJdu3BfGQ2ck6p9q6E30dTrsYAHQCd3XxcOrwc6hcN11ZfUusOveScQHDGntLawGWQmsBF4n+BIZKu7V9Sy/ppth9MLgPb7u6bQo8Avgarwdfs0qcuBsWY2zcxuDMelev/qCeQBz4VNWs+YWVYa1FXtcuCVcDilNbn7GuAPwEpgHcG+Mo0U7VsNPeDTjgcftyk799TMWgKvAz9x98LYaamozd0r3b0/wRHzIOCYA7n92pjZ+cBGd5+W6lpqMdzdBwDnAj8ys5NjJ6Zo/8okaJb8m7ufABQRNH+kui7CtuwLgf/deVoqagrb/C8i+FA8DMgCRhzIGmI19IBPl8cCbjCzzgDh743h+LrqS0rdZtaYINxfcvc30qk2d98KjCP4etrWzKqfRRC7/ppth9PbAJuTUNNJwIVmlgv8m6CZ5s9pUFf1ESDuvhF4k+BDMdV/w9XAanefHL5+jSDwU10XBB+E0919Q/g61TWdCSx39zx3LwfeINjfUrJvNfSAT5fHAo4CqnvfryFo/64ef3XYgz8EKAi/Pr4HnG1mh4Sf+GeH4/aamRnwD2CBuz+SDrWZWbaZtQ2HmxP0CSwgCPpL6qiputZLgI/Co7BRwOXhGQc9gSOBKXtTE4C73+7uXd29B8E+85G7X5nquswsy8xaVQ8TvPdzSfH+5e7rgVVmdnQ46gxgfqrrCl3Bl80z1dtOZU0rgSFm1iL8P1n9XqVm39rXDo5U/xD0jn9B0LZ7xwHY3isEbWvlBEc21xO0mX0ILAY+ANqF8xrwRFjbHGBgzHquA5aEP9/dD3UNJ/g6OhuYGf6cl8ragH7AjLCmucBvwvG9wp11CcFX66bh+Gbh6yXh9F4x67ojrHURcO5+/Hueypdn0aS0rnD7s8KfedX7c5rsX/2BnPBv+RbBGScprYug+WMz0CZmXDq8V/cCC8N9/p8EZ8KkZN/SrQpERCKqoTfRiIhIHRTwIiIRpYAXEYkoBbyISEQp4EVEIkoBLwcdM6u04A6Es8xsupkN2838bc3sh/VY73gzS7sHO8vBSwEvB6Nid+/v7scT3NTpgd3M35bgrn8iDYoCXg52rYEtENzHx8w+DI/q55jZReE8DwJHhEf9D4fz/iqcZ5aZPRizvm9ZcA/8L8zsawf2nyISL3P3s4hETvPwDpfNCG4Ze3o4vgT4ursXmlkH4HMzG0VwY62+Htw0DTM7l+CGUoPdfYeZtYtZd6a7DzKz84C7Ce5NIpISCng5GBXHhPVQ4EUz60twOfvvwjs4VhHcnrVTLcufCTzn7jsA3D0/Zlr1Td6mETw3QCRlFPByUHP3z8Kj9WyCe/dkA1919/LwbpPN9nCVpeHvSvT/S1JMbfByUDOzYwge+baZ4FatG8NwP43gEXAA2wgeg1jtfeC7ZtYiXEdsE41I2tARhhyMqtvgIWiWucbdK83sJeC/ZjaH4M6JCwHcfbOZTbTgQevvuPsvzKw/kGNmZcDbwK8P+L9CZDd0N0kRkYhSE42ISEQp4EVEIkoBLyISUQp4EZGIUsCLiESUAl5EJKIU8CIiEfX/AZp4zn2Pf2HmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 0: Why does Earth orbit the Sun?\n",
      "Model output: Why does Earth orbit the Sun? I want to get the static that the same the same the same that the constructor and the statement the statistical the are the same the and the test to the statement the statistical the and the statistical the an entire the tornation the statistical the and the torgeth the statistical the statistical the and the torger the statical the statistical the and the tord the tord the torn the topical the torn the to the topical the tory to the topical the topical the to the tory any the ton the topperan the are any any the any and the the tole the to the the tore the tolly the the ton the the tolly the the ton the the ton the the the ton the the ton the the ton the the the ton the the ton the the the ton the the the ton the the ton the the the ton the the ton the the the the ton the ton the the ton the the the the the the ton t ton the ton the the the the the ton the the the then t then ton the t the the ton the the t the the ton the ton ton t t ton the the the the the the the t ton the the the t the ton ton the t ton<CUTOFF>\n",
      "\n",
      "Prompt 1: How to use ChatGPT?\n",
      "Model output: How to use ChatGPT? I want to constructor a control and the control that the constructor that the constructor and the statement the statistical of the statistical of the statistical statically the and the statistical the and the statical of the statistical the and the torgether and the statistical that the same the same that the same that the same the same that the same that the same the any the are any the are any the are any the are any the are any the are any allys the are any ally the are any ally the are any ally the are any any ally the and the the south the the tore sould the the to sould the the tough ton the to the the to solly the the ton the the the ton the the ton the ton the the the the the ton the the ton the the ton the the ton the the ton the the the ton the the the ton the the ton the ton the ton the the the ton the ton the the the ton the the the ton the the ton the the the ton t then the the the ton the ton the t ton the the the the ton ton ton t the the the ton t the the ton the the the t the the the ton the<CUTOFF>\n",
      "\n",
      "Prompt 2: My code does not work. What should I do?\n",
      "Model output: My code does not work. What should I do? I have a lot of the book of the based on the same of the same of the statement of the statistical the and the statistical the are the statistical the and the torgeth and the statistical the statistical the and the statistical the and the torgeth an all the statistical the statistical the and the statistical the and the tords and the top the topical the tord the tory to the topical the tory to the topical the topical the tory and the tory to the topperan the are any any the tone the tore any any the are any any any any any any any any any any any any any any any any any any any any any any any any any any any and any any any an an any an an an an an an an an a an a a a a a a a a a a a s a a a a s a a a a s a a a s a a a a a s a a a a a a a a a a a s a a a s a a a a a a a s a a a a a a s a a a a a s a a a a a a a a a a a a a a s a a a a a a a a a a a s a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a <CUTOFF>\n",
      "\n",
      "Prompt 3: Why is this code not working: `1+\"A\"`?\n",
      "Model output: Why is this code not working: `1+\"A\"`?\n",
      "\n",
      "Prompt 4: Why is Java better than Python?\n",
      "Model output: Why is Java better than Python? I want to get a lot and a programming and I wanted to learn a lot of the like of the language of the language and the program language the language a lot of the language of the language of the statement of the statience of the statistical of the statistical of the statistical of the statistical of the statistical of the statistical the and the statistical the and the torday and the torday the contern of the tor and the tory and the tory are to the are any the are any the are any the are any ally the are any ally the and the the salle the to be the the stoler the tolly the the ton the the tolly the the ton the the ton the the ton the the tow the ton the the tow the the the ton the the ton the the the tow the the the the ton the the ton the the the the the ton ton the ton the the the ton the the the ton the the the the ton the the ton the the ton the the the the ton the the the the the the the ton t ton the the the the the ton ton the ton the the t the the the the the ton the the t the ton the ton the ton t to<CUTOFF>\n",
      "\n",
      "Prompt 5: Why is Python better than Java?\n",
      "Model output: Why is Python better than Java? I want to learn a lot of the programming language a lot of the language and I want to be a lot of the programming language and a lot of the language of the language of the language of the one the one the one the and the torget and the statistical of the statistical of the statistical of the statistical of the statistical the and the statement of the statistical the are and the standare that the standare that store of the standare than and the same the same the and the stan the stand the stan the stare and the salle the stolly the the stolle the the tore the toll the to the the toll the to the the toll the tolly the the ton the the to the the the ton the tow the the the tow the the the ton the the tow the the tow the the the tow the the ton the the the the tow the the ton the the tow the the the the ton the the ton ton the the ton the the the the ton ton the the the the the the the the ton the the ton ton the t the ton the ton the the ton the the ton the the the the ton t the the the ton ton t the ton the ton<CUTOFF>\n",
      "\n",
      "Prompt 6: What is the purpose of the main() function in C?\n",
      "Model output: What is the purpose of the main() function in C? I am a lot of the context of the statistical the array and the statistical that the same the are the array and the same the are the and the tordial the statistical the and the torgeth and the statical the statistical of the statistical the and the torgeth and the top the statis that the same the same that the same that the same that the same that any the same the any the are any the are the stand that the stand the sting the are any any the are any allyst any the the stand the the stolly the the stolly the tore the tolly the to the the tought to the the to the the toll to the the toolly the the toon the the the towolly the the ton the to the the the the ton the ton the the the the ton the tow the the the the the ton ton the the the ton the the ton the ton the the the ton the the ton the the the ton the the ton ton the the the ton the the ton the ton ton the the the the the the ton t ton the ton the the ton the ton the the ton the the ton the ton t the the ton t the the ton ton the ton t ton ton t ton ton the<CUTOFF>\n",
      "\n",
      "Prompt 7: What is coding?\n",
      "Model output: What is coding? I am learning to be a lot of the programming language and I want to be a lot of the like to learn and the language the statement of the statistical of the statistical of the statistical of the statistical of the statistical of the statistical of the statistical the and the statistical of the statistical of the statistical of the statistical the and the top the statistical the and the tords and the topical the torn the topical the torn the torn the tope the tore and the tore any the tory are the any any the are any any any ally the are any any the any any any any any any any any ale the and the to sour ally the the the ton the the the tore sough that ton the the ton the the the ton the the ton the the ton the the ton the the the ton the ton the the the ton the the the ton the the ton ton the the the the ton the the the ton the the the ton the the ton the the ton the the the the the the the the the the the than ton t ton the the the ton the ton ton the the the the the the the ton the the the the the ton ton t <CUTOFF>\n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 4848/8060 [1:02:54<41:23,  1.29it/s]"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "epoch_losses = []\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    \n",
    "    batch_losses = []\n",
    "    for data in tqdm.tqdm(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        data = data.to(device)\n",
    "\n",
    "        output, loss = model(data, True)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_losses.append(loss.item())\n",
    "\n",
    "        \n",
    "    epoch_losses.append(sum(batch_losses)/len(batch_losses))\n",
    "\n",
    "    plt.plot(range(len(batch_losses)),batch_losses)\n",
    "    plt.xlabel(\"Batch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Batch loss\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(range(len(epoch_losses)), epoch_losses)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Epoch loss\")\n",
    "    plt.show()\n",
    "\n",
    "    torch.save(model, prefix_models+f\"model_E{epoch}\")\n",
    "\n",
    "    with open(prefix_models+\"losses.txt\", \"a\") as f:\n",
    "        f.write(f\"{epoch_losses[-1]}\\n\")\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, prompt in enumerate(prompts):\n",
    "            print(f\"Prompt {i}: {prompt}\")\n",
    "            output=generate(prompt)\n",
    "            print(f\"Model output: {output}\")\n",
    "            print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUracnfcZSLX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torch.load(prefix_models+\"model_E9\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, prompt in enumerate(prompts):\n",
    "        print(f\"Prompt {i}: {prompt}\")\n",
    "        output=generate(prompt)\n",
    "        print(f\"Model output: {output}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r31WSN9YiTuZ"
   },
   "outputs": [],
   "source": [
    "import builtins\n",
    "while True:\n",
    "    prompt = builtins.input(\">>> \")\n",
    "    output=generate(prompt)\n",
    "    print(f\"Model output: {output}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
